# ğŸ­ SentimentX: A Multimodal AI System for Emotion Recognition

**SentimentX** is a cutting-edge AI system that understands human emotions through **video**, **audio**, and **text**. It uses powerful deep learning models like CNNs, Transformers, and BERT, and wraps everything in a sleek and user-friendly **Tkinter GUI**.



---

## ğŸ’¡ Key Features

- ğŸ¥ **Video Emotion Detection**  
  Real-time facial emotion recognition using CNN + Spatial Transformer Network.

- ğŸ™ï¸ **Audio Sentiment Analysis**  
  Emotion prediction from voice using a hybrid Transformer-CNN model.

- ğŸ“ **Text Sentiment Analysis**  
  Sentiment classification using BERT/DistilBERT fine-tuned models.

- ğŸ§  **Unified GUI**  
  A full-screen Tkinter interface to interact with all three modalities.

- ğŸ”Š Voice response with `pyttsx3`  
  Emotion results are announced via TTS for video predictions.

---

## ğŸ—‚ï¸ Project Structure

SentimentX/
â”œâ”€â”€ Main.py                      # ğŸ§  Main GUI application
â”œâ”€â”€ Execution.txt                # âœ… Process flow checklist

â”œâ”€â”€ video_analysis/              # ğŸ¥ Video Emotion Recognition
â”‚   â”œâ”€â”€ sentivideo.py            # Real-time webcam emotion detection
â”‚   â”œâ”€â”€ deep_emotion.py          # CNN + Spatial Transformer Network model
â”‚   â”œâ”€â”€ train_emotion_model.py   # Training script for CNN model
â”‚   â”œâ”€â”€ data_load.py             # Custom dataset class for image loading
â”‚   â”œâ”€â”€ prepare_dataset.py       # Dataset preprocessor (CSV generator)
â”‚   â””â”€â”€ deep_emotion-*.pt        # Trained model file (weights)

â”œâ”€â”€ audio_analysis/              # ğŸ™ï¸ Audio Sentiment Analysis
â”‚   â”œâ”€â”€ torchscript.py           # Converts model to TorchScript (.pt)
â”‚   â”œâ”€â”€ emotion_model.pth        # Pretrained PyTorch model

â”œâ”€â”€ text_analysis/               # ğŸ“ Text Sentiment Analysis
â”‚   â”œâ”€â”€ sentitext.py             # DistilBERT model training & evaluation
â”‚   â”œâ”€â”€ sentitext_load.py        # BERT model loader for inference
â”‚   â”œâ”€â”€ sentimentds.csv          # Sample sentiment dataset
â”‚   â””â”€â”€ bert_sentiment_model/    # Saved BERT model + label_map.json

â”œâ”€â”€ requirements.txt             # ğŸ“¦ Python dependencies list
â”œâ”€â”€ README.md                    # ğŸ“˜ Project documentation
â””â”€â”€ LICENSE                      # âš–ï¸ MIT License


---

## â–¶ï¸ Execution Flow

To set up and run this project, follow these steps **in order**:

1. `prepare_dataset.py`  
   â¤ Converts CK+ dataset folders into `Train1.csv` and `Test_1.csv`.

2. `train_emotion_model.py`  
   â¤ Trains and saves the CNN model (`deep_emotion-100-128-0.005.pt`).

3. `deep_emotion.py`  
   â¤ Contains model architecture used in training and inference.

4. `data_load.py`  
   â¤ Provides dataset class used by PyTorch's DataLoader.

5. `sentivideo.py`  
   â¤ Starts webcam-based real-time facial emotion recognition.

6. `Main.py`  
   â¤ Runs the GUI combining all three emotion detection modules.

---

## ğŸš€ Run the Application


python Main.py


---

## ğŸ§‘â€ğŸ’» Developers

ğŸ‘¨â€ğŸ’» **Dayanand M K** â€” *Lead Developer*  
ğŸ‘¨â€ğŸ’» Balaji S  
ğŸ‘¨â€ğŸ’» Praveen K S  

Batch: 9 â€” 2nd Year CSE (AI & ML)  
Vel Tech High Tech Dr. Rangarajan Dr. Sakunthala Engineering College

---

## ğŸ”® Future Scope

- Fuse results from all three modalities to make smarter emotional decisions  
- Add support for complex, subtle emotions  
- Build VR/AR integrations for immersive feedback

---

## ğŸ“Œ Screenshot
![Screenshot 2025-04-01 215227](https://github.com/user-attachments/assets/06cc0b35-0db2-4dc2-a6e1-05214e9f2f1a)
![Screenshot 2025-04-01 215806](https://github.com/user-attachments/assets/31edfbfd-f7c8-4117-824f-9222daaa3cde)
![Screenshot 2025-04-01 224442](https://github.com/user-attachments/assets/2cbc8dbe-dd16-4d46-ab39-d8e7398f807e)
![Screenshot 2025-04-01 224045](https://github.com/user-attachments/assets/b8e28af4-3418-4dc6-9b10-d159512a2233)

---
