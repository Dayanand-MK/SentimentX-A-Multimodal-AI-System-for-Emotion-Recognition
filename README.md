# ğŸ­ SentimentX: A Multimodal AI System for Emotion Recognition

**SentimentX** is a cutting-edge AI system that understands human emotions through **video**, **audio**, and **text**. It uses powerful deep learning models like CNNs, Transformers, and BERT, and wraps everything in a sleek and user-friendly **Tkinter GUI**.



---

## ğŸ’¡ Key Features

- ğŸ¥ **Video Emotion Detection**  
  Real-time facial emotion recognition using CNN + Spatial Transformer Network.

- ğŸ™ï¸ **Audio Sentiment Analysis**  
  Emotion prediction from voice using a hybrid Transformer-CNN model.

- ğŸ“ **Text Sentiment Analysis**  
  Sentiment classification using BERT/DistilBERT fine-tuned models.

- ğŸ§  **Unified GUI**  
  A full-screen Tkinter interface to interact with all three modalities.

- ğŸ”Š Voice response with `pyttsx3`  
  Emotion results are announced via TTS for video predictions.

---

## ğŸ—‚ï¸ Project Structure


SentimentX/
â”‚
â”œâ”€â”€ Main.py                     # ğŸ§  GUI entry point
â”œâ”€â”€ Execution.txt               # âœ… Ordered process flow
â”‚
â”œâ”€â”€ video_analysis/
â”‚   â”œâ”€â”€ sentivideo.py           # Video emotion detection logic
â”‚   â”œâ”€â”€ deep_emotion.py         # CNN + STN model
â”‚   â”œâ”€â”€ train_emotion_model.py  # Model training script
â”‚   â”œâ”€â”€ data_load.py            # Custom PyTorch dataset
â”‚   â”œâ”€â”€ prepare_dataset.py      # Dataset preprocessing (CSV)
â”‚   â””â”€â”€ deep_emotion-100-128-0.005.pt
â”‚
â”œâ”€â”€ audio_analysis/
â”‚   â”œâ”€â”€ torchscript.py          # Converts model to TorchScript
â”‚   â”œâ”€â”€ emotion_model.pth       # Pretrained model for audio emotion
â”‚
â”œâ”€â”€ text_analysis/
â”‚   â”œâ”€â”€ sentitext.py            # Training + prediction using DistilBERT
â”‚   â”œâ”€â”€ sentitext_load.py       # Model loader (BERT version)
â”‚   â”œâ”€â”€ bert_sentiment_model/   # Saved BERT model and label_map.json
â”‚   â””â”€â”€ sentimentds.csv         # Sample dataset


---

## â–¶ï¸ Execution Flow

To set up and run this project, follow these steps **in order**:

1. `prepare_dataset.py`  
   â¤ Converts CK+ dataset folders into `Train1.csv` and `Test_1.csv`.

2. `train_emotion_model.py`  
   â¤ Trains and saves the CNN model (`deep_emotion-100-128-0.005.pt`).

3. `deep_emotion.py`  
   â¤ Contains model architecture used in training and inference.

4. `data_load.py`  
   â¤ Provides dataset class used by PyTorch's DataLoader.

5. `sentivideo.py`  
   â¤ Starts webcam-based real-time facial emotion recognition.

6. `Main.py`  
   â¤ Runs the GUI combining all three emotion detection modules.

---

## ğŸš€ Run the Application


python Main.py


---

## ğŸ§‘â€ğŸ’» Developers

ğŸ‘¨â€ğŸ’» **Dayanand M K** â€” *Lead Developer*  
ğŸ‘¨â€ğŸ’» Balaji S  
ğŸ‘¨â€ğŸ’» Praveen K S  

Batch: 9 â€” 2nd Year CSE (AI & ML)  
Vel Tech High Tech Dr. Rangarajan Dr. Sakunthala Engineering College

---

## ğŸ”® Future Scope

- Fuse results from all three modalities to make smarter emotional decisions  
- Add support for complex, subtle emotions  
- Build VR/AR integrations for immersive feedback

---

## ğŸ“Œ Screenshot
![Screenshot 2025-04-01 215227](https://github.com/user-attachments/assets/06cc0b35-0db2-4dc2-a6e1-05214e9f2f1a)
![Screenshot 2025-04-01 215806](https://github.com/user-attachments/assets/31edfbfd-f7c8-4117-824f-9222daaa3cde)
![Screenshot 2025-04-01 215825](https://github.com/user-attachments/assets/b39204d1-334a-42cc-a8eb-347f31c749b3)
![Screenshot 2025-04-01 224045](https://github.com/user-attachments/assets/b8e28af4-3418-4dc6-9b10-d159512a2233)



---
